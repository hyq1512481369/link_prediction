{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d38cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "torch.__version__\n",
    "import torch.nn as nn\n",
    "import torch_geometric\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.loader import NeighborSampler\n",
    "from torch_geometric.utils import degree\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from torch_geometric.nn import GCNConv,SAGEConv\n",
    "from torch_geometric.nn import GATConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bc89df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KGDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, triples, entity2id, relation2id):\n",
    "        self.triples = triples\n",
    "        self.entity2id = entity2id\n",
    "        self.relation2id = relation2id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        head, relation, tail = self.triples[idx]\n",
    "        head_id = self.entity2id[head]\n",
    "        relation_id = self.relation2id[relation]\n",
    "        tail_id = self.entity2id[tail]\n",
    "        return head_id, relation_id, tail_id\n",
    "\n",
    "class predDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, triples, entity2id, relation2id):\n",
    "        self.triples = triples\n",
    "        self.entity2id = entity2id\n",
    "        self.relation2id = relation2id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        head, relation = self.triples[idx]\n",
    "        head_id = self.entity2id[head]\n",
    "        relation_id = self.relation2id[relation]\n",
    "        return head_id, relation_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "863d97db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dataset2Graph(dataset):\n",
    "    m={}\n",
    "    e_id=[]\n",
    "    edge_index=[]\n",
    "    for idx in range(len(dataset)):\n",
    "        head_id, relation_id, tail_id =dataset[idx]\n",
    "        if m.get((head_id,relation_id,tail_id),0)!=1:\n",
    "            edge_index.append([head_id, tail_id])  # 添加头实体和尾实体作为连接\n",
    "            e_id.append([relation_id])\n",
    "            m[(head_id,relation_id,tail_id)]=1\n",
    "    # 转换为tensor\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    e_id = torch.tensor(e_id,dtype=torch.long).squeeze()  # 保持关系ID作为边属性\n",
    "\n",
    "    graph = torch_geometric.data.Data(edge_index=edge_index,e_id=e_id)\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bb59221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 1252550], e_id=[1252550], num_nodes=249746, num_edges=1252550, n_id=[249746])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_csv(\"MyData/train_R.csv\")[['Head', 'Relation', 'Tail']]\n",
    "va_set = pd.read_csv(\"MyData/vali_R.csv\")[['Head', 'Relation', 'Tail']]\n",
    "train = [tuple(row) for row in train_set.itertuples(index=False)]\n",
    "va = [tuple(row) for row in va_set.itertuples(index=False)]\n",
    "test_set=pd.read_csv(\"MyData/test.csv\")[['Head','Relation']]\n",
    "test=[tuple(row) for row in test_set.itertuples(index=False)]\n",
    "relation2text = pd.read_csv(\"MyData/relation.csv\", encoding='UTF-8')[['Name', 'Text', 'ID']]\n",
    "entity2text = pd.read_csv(\"MyData/entity.csv\", encoding='UTF-8')[['Name', 'Text', 'ID']]\n",
    "eDic = entity2text.set_index('Name')['ID'].to_dict()\n",
    "rDic = relation2text.set_index('Name')['ID'].to_dict()\n",
    "\"\"\"\n",
    "此时：\n",
    "va,test,train=[tuple]\n",
    "xDic=['name':ID]\n",
    "\n",
    "\"\"\"\n",
    "KG=KGDataset(train,eDic,rDic)\n",
    "predict=predDataset(train,eDic,rDic)\n",
    "train=KGDataset(train,eDic,rDic)\n",
    "vali=KGDataset(va,eDic,rDic)\n",
    "test=predDataset(test,eDic,rDic)\n",
    "graph=Dataset2Graph(KG)\n",
    "graph.num_nodes=len(eDic)\n",
    "graph.num_edges=len(graph.edge_index[0])\n",
    "graph.n_id =torch.tensor(list(eDic.values()))\n",
    "graph=graph.to(device)\n",
    "#graph.x=torch.tensor([[i] for i in range(len(eDic))])\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da968a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Frame(nn.Module):\n",
    "    def vali_model(self,vali):\n",
    "        self.eval()\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        vali_loader = torch.utils.data.DataLoader(vali,batch_size=self.batch_size, shuffle=False)\n",
    "        with torch.no_grad():\n",
    "            for head, relation, tail in vali_loader:\n",
    "                head, relation, tail = head.to(self.device), relation.to(self.device), tail.to(self.device)\n",
    "                #print(head.size(),head)\n",
    "                sub=self.get_sub(head)\n",
    "                #开始前向\n",
    "                new_graph=self.network(sub)\n",
    "                sorted_tensor, idx = new_graph.n_id.sort()\n",
    "                positions = torch.searchsorted(sorted_tensor, head)\n",
    "                x=new_graph.x[positions]\n",
    "                r=self.network.relation_embedding(relation)\n",
    "                x=torch.cat((x,r),dim=1)\n",
    "                output = self.fc(x)\n",
    "                predicted_tail = torch.argmax(output, dim=1)\n",
    "                total_correct += (predicted_tail == tail).sum().item()\n",
    "                total_samples += len(tail)\n",
    "        accuracy = total_correct / total_samples\n",
    "        return accuracy \n",
    "    \n",
    "    def predict_model(self,test,entity2id,top_k=10,name=\"\"):\n",
    "        self.eval()\n",
    "        id2entity = {v: k for k, v in entity2id.items()}\n",
    "        results = []\n",
    "        test_loader = torch.utils.data.DataLoader(test,batch_size=self.batch_size, shuffle=False)\n",
    "        with torch.no_grad():\n",
    "            for head, relation in test_loader:\n",
    "                head, relation = head.to(self.device), relation.to(self.device)\n",
    "                #print(head.size(),head)\n",
    "                sub=self.get_sub(head)\n",
    "                #开始前向\n",
    "                new_graph=self.network(sub)\n",
    "                sorted_tensor, idx = new_graph.n_id.sort()\n",
    "                positions = torch.searchsorted(sorted_tensor, head)\n",
    "                x=new_graph.x[positions]\n",
    "                r=self.network.relation_embedding(relation)\n",
    "                x=torch.cat((x,r),dim=1)\n",
    "                output = self.fc(x)\n",
    "                _, top_indices = torch.topk(output, top_k, dim=1)\n",
    "\n",
    "                for idx_list in top_indices:\n",
    "\n",
    "                    top_entities = [id2entity[idx.item()] for idx in idx_list]\n",
    "                    results.append(top_entities)\n",
    "        results = pd.DataFrame(results)\n",
    "        r=pd.concat([test_set,results],axis=1)\n",
    "        r.to_csv(\"./r/result\"+name+\".tsv\",header=None,sep='\\t',index=False)\n",
    "        #return results\n",
    "    \n",
    "    \n",
    "    def __init__(self, graph,num_entities,num_relations,\n",
    "                 lr=0.0001, embed_dim=16,batch_size=512,\n",
    "                 num_epochs=25, num_layers=4,heads=2):\n",
    "        super(Frame, self).__init__()\n",
    "        self.graph=graph\n",
    "        self.reversed_graph = copy.deepcopy(self.graph)\n",
    "        # 反转edge_index\n",
    "        self.reversed_graph.edge_index = self.reversed_graph.edge_index[[1, 0], :]\n",
    "        self.lr=lr\n",
    "        self.batch_size=batch_size\n",
    "        self.num_epochs=num_epochs\n",
    "        self.num_layers=num_layers\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.num_entities =num_entities\n",
    "        self.num_relations =num_relations\n",
    "        self.embed_dim=embed_dim\n",
    "       \n",
    "        \n",
    "        \n",
    "        self.loss = torch.nn.BCEWithLogitsLoss()\n",
    "        #待填\n",
    "        self.network=network(num_entities=num_entities,num_relations=num_relations,embed_dim=embed_dim,num_layers=num_layers,heads=heads).to(self.device)\n",
    "        self.fc = nn.Linear(embed_dim*2, self.num_entities).to(self.device)\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    \n",
    "        \n",
    "    def train_model(self,train,vali,test,entity2id,flag=False):\n",
    "        best_acc=0\n",
    "        for epoch in range(self.num_epochs):\n",
    "            \n",
    "            self.train()\n",
    "            train_loader = torch.utils.data.DataLoader(train,batch_size=self.batch_size, shuffle=True)\n",
    "            progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{self.num_epochs}', leave=True)\n",
    "            for head, relation, tail in progress_bar:\n",
    "                for _ in range(10):\n",
    "                    torch.cuda.empty_cache()\n",
    "                self.optimizer.zero_grad()\n",
    "                head, relation, tail = head.to(self.device), relation.to(self.device), tail.to(self.device)\n",
    "                sub=self.get_sub(head)\n",
    "                #开始前向\n",
    "                new_graph=self.network(sub)\n",
    "                sorted_tensor, idx = new_graph.n_id.sort()\n",
    "                positions = torch.searchsorted(sorted_tensor, head)\n",
    "                x=new_graph.x[positions]\n",
    "                r=self.network.relation_embedding(relation)\n",
    "                x=torch.cat((x,r),dim=1)\n",
    "                output = self.fc(x)\n",
    "                loss1 = self.criterion(output, tail)\n",
    "                loss2=self.criterion(output/1.1, tail)\n",
    "                if flag:\n",
    "                    sub=self.get_sub(tail)\n",
    "                    #开始前向\n",
    "                    new_graph=self.network(sub)\n",
    "                    sorted_tensor, idx = new_graph.n_id.sort()\n",
    "                    positions = torch.searchsorted(sorted_tensor, tail)\n",
    "                    x=new_graph.x[positions]\n",
    "                    r=self.network.relation_embedding(relation)\n",
    "                    x=torch.cat((x,-r),dim=1)\n",
    "                    output = self.fc(x)\n",
    "                    loss3 = self.criterion(output, head)\n",
    "                    #print(loss)\n",
    "                    loss=loss1*0.8+loss2*0.1+loss3*0.1\n",
    "                else:\n",
    "                    loss=loss1*0.95+loss2*0.05\n",
    "                loss.backward()\n",
    "                #loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                \n",
    "                \n",
    "            self.eval()\n",
    "            acc = self.vali_model(vali)\n",
    "            if best_acc<acc:\n",
    "                best_acc=acc\n",
    "                self.predict_model(test,entity2id=entity2id,name=str(acc))\n",
    "                \n",
    "            lr=self.lr\n",
    "            if acc>0.5:\n",
    "                self.lr=0.001\n",
    "            elif acc>0.40:\n",
    "                self.lr=0.005\n",
    "            elif acc>0.35:\n",
    "                self.lr=0.03\n",
    "            elif acc>0.3:\n",
    "                self.lr=0.05\n",
    "            if lr!=self.lr:\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                        param_group['lr'] =self.lr\n",
    "            tqdm.write(f'Epoch {epoch + 1}, Loss: {loss.item():.3f}, Acc: {acc * 100 :.2f}%')\n",
    "            progress_bar.refresh()\n",
    "    \n",
    "    def get_sub(self,head):\n",
    "        # 使用torch.isin生成一个布尔掩码，其中包含的位置为True\n",
    "        mask = torch.isin(self.graph.n_id, head.to(self.device))\n",
    "        # 使用torch.nonzero找到True值的索引\n",
    "        nodes= torch.nonzero(mask, as_tuple=True)[0]\n",
    "        loader = NeighborLoader(self.graph,\n",
    "                                input_nodes=nodes, \n",
    "                                num_neighbors=[-1],\n",
    "                                batch_size=self.graph.num_nodes,\n",
    "                                shuffle=False)\n",
    "        for batch in loader:\n",
    "                return batch\n",
    "            # 交换行来反转方向\n",
    "        reversed_loader = NeighborLoader(self.reversed_graph,\n",
    "                                input_nodes=nodes, \n",
    "                                num_neighbors=[-1],\n",
    "                                batch_size=self.graph.num_nodes,\n",
    "                                shuffle=False)\n",
    "        for batch, reversed_batch in zip(loader, reversed_loader):\n",
    "            #不会循环，仅一次\n",
    "            # 合并两个批次的数据\n",
    "            all=torch.tensor(list(set(batch.n_id.tolist()+reversed_batch.n_id.tolist())))\n",
    "            sub=self.graph.subgraph(all).to(device)\n",
    "            return sub\n",
    "    \n",
    "        \n",
    "class network(nn.Module):\n",
    "    def __init__(self,num_entities,num_relations,embed_dim,num_layers,heads):\n",
    "        self.embed_dim=embed_dim\n",
    "        self.num_relations=num_relations\n",
    "        super(network, self).__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.entity_embedding = nn.Embedding(num_entities, embed_dim).to(self.device)\n",
    "        self.relation_embedding = nn.Embedding(num_relations, embed_dim).to(self.device)\n",
    "        \n",
    "        self.gat_layers = torch.nn.ModuleList([\n",
    "            GATConv(embed_dim, embed_dim, heads=heads)] )\n",
    "        for _ in range(num_layers-2):\n",
    "            self.gat_layers.append(GATConv(embed_dim*heads, embed_dim*heads, heads=heads,concat=False))\n",
    "        self.gat_layers.append(GATConv(embed_dim*heads, embed_dim, heads=heads,concat=False))\n",
    "\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        for _ in range(int(num_layers/2)):\n",
    "            self.layers.append(GCNConv(embed_dim, embed_dim))\n",
    "            self.layers.append(SAGEConv(embed_dim, embed_dim))\n",
    "\n",
    "\n",
    "    def forward(self,graph):\n",
    "        x=self.entity_embedding(graph.n_id) \n",
    "\n",
    "        for layer in self.gat_layers:\n",
    "            #print(x.size())\n",
    "            x = F.relu(layer(x, graph.edge_index))\n",
    "\n",
    "        graph.x=x\n",
    "        \n",
    "        return graph\n",
    "\n",
    "\n",
    "frame=Frame(graph=graph,num_entities=len(eDic),num_relations=len(rDic),\n",
    "           lr=0.1, embed_dim=8,batch_size=1000,\n",
    "                 num_epochs=50, num_layers=3,heads=1\n",
    "           )\n",
    "\n",
    "frame.train_model(train,vali,entity2id=eDic,test=test,flag=False)\n",
    "#result=frame.predict_model(test,entity2id=eDic,name=str(2.1))\n",
    "#result = pd.DataFrame(result)\n",
    "#r=pd.concat([test_set,result],axis=1)\n",
    "#r.to_csv(\"result.tsv\",header=None,sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8cc361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0652ef15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b8cc0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
