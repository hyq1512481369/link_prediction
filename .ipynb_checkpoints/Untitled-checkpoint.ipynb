{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c45ffb05",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from model import *\n",
    "with open(\"./MyData/entity_embedding.json\", 'r', encoding='utf-8') as file:\n",
    "        entity_json = json.load(file)\n",
    "with open(\"./MyData/relation_embedding.json\", 'r', encoding='utf-8') as file:\n",
    "        relation_json = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41a5cd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u210110113/.conda/envs/GEO/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import  DataLoader\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54165703",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KGDataset(Dataset):\n",
    "    def __init__(self, triples, entity2id, relation2id):\n",
    "        self.triples = triples\n",
    "        self.entity2id = entity2id\n",
    "        self.relation2id = relation2id\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.triples)\n",
    "\n",
    "    def get(self, idx):\n",
    "        head, relation, tail = self.triples[idx]\n",
    "        head_id = self.entity2id[head]\n",
    "        relation_id = self.relation2id[relation]\n",
    "        tail_id = self.entity2id[tail]\n",
    "        data = Data(x=head_id, edge_index=relation_id, y=tail_id)\n",
    "        return data\n",
    "\n",
    "class PredDataset(Dataset):\n",
    "    def __init__(self, triples, entity2id, relation2id):\n",
    "        self.triples = triples\n",
    "        self.entity2id = entity2id\n",
    "        self.relation2id = relation2id\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.triples)\n",
    "\n",
    "    def get(self, idx):\n",
    "        head, relation = self.triples[idx]\n",
    "        head_id = self.entity2id[head]\n",
    "        relation_id = self.relation2id[relation]\n",
    "        data = Data(x=head_id, edge_index=relation_id)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea622378",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module)\n",
    "    def __init__(self, triples, entity2id, relation2id, entity_dim=128, relation_dim=128, lr=0.001, batch_size=32,\n",
    "                 num_epochs=10, num_gnn_layers=5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0125d692",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrieveAndReadFramework(nn.Module):\n",
    "    def __init__(self, triples, entity2id, relation2id, entity_dim=128, relation_dim=128, lr=0.001, batch_size=32,\n",
    "                 num_epochs=10, num_gnn_layers=5):\n",
    "        super(RetrieveAndReadFramework, self).__init__()\n",
    "        self.entity2id = entity2id\n",
    "        self.relation2id = relation2id\n",
    "        self.entity_dim = entity_dim\n",
    "        self.relation_dim = relation_dim\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        self.train_dataset = KGDataset(triples, entity2id, relation2id)\n",
    "        self.train_loader = DataLoader(self.train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        self.num_entities = len(entity2id)\n",
    "        self.num_relations = len(relation2id)\n",
    "\n",
    "        self.entity_embedding = nn.Embedding(self.num_entities, entity_dim).to(self.device)\n",
    "        self.relation_embedding = nn.Embedding(self.num_relations, relation_dim).to(self.device)\n",
    "        self.gnn_layers = nn.ModuleList([GCNConv(entity_dim, entity_dim) for _ in range(num_gnn_layers)]).to(self.device)\n",
    "        self.fc = nn.Linear(entity_dim + relation_dim, self.num_entities).to(self.device)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def create_graph_data(self, nodes, triples):\n",
    "        edge_index = []\n",
    "        edge_attr = []\n",
    "        for head, relation, tail in triples:\n",
    "            head_id = self.entity2id[head]\n",
    "            relation_id = self.relation2id[relation]\n",
    "            tail_id = self.entity2id[tail]\n",
    "            if head_id in nodes and tail_id in nodes:\n",
    "                edge_index.append([head_id, tail_id])\n",
    "                edge_attr.append(relation_id)\n",
    "        \n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.long)\n",
    "        return Data(x=self.entity_embedding.weight[nodes], edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        for layer in self.gnn_layers:\n",
    "            x = layer(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "    def train_model(self, train_triples, val_triples):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.train()\n",
    "            progress_bar = tqdm(self.train_loader, desc=f'Epoch {epoch + 1}/{self.num_epochs}', leave=True)\n",
    "            for head, relation, tail in progress_bar:\n",
    "                print(head.size())\n",
    "                head, relation, tail = head.to(self.device), relation.to(self.device), tail.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                nodes = list(set(head.tolist()))\n",
    "                data = self.create_graph_data(nodes, train_triples).to(self.device)\n",
    "                all_embed = self.forward(data)\n",
    "                head_embed = all_embed[head]\n",
    "                relation_embed = self.relation_embedding(relation)\n",
    "                embed = torch.cat((head_embed, relation_embed), dim=1)\n",
    "                output = self.fc(embed)\n",
    "                loss = self.criterion(output, tail)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            acc = self.evaluate_model(val_triples)\n",
    "            tqdm.write(f'Epoch {epoch + 1}, Loss: {loss.item():.3f}, Acc: {acc * 100 :.2f}%')\n",
    "            progress_bar.refresh()\n",
    "\n",
    "    def evaluate_model(self, val_triples):\n",
    "        eval_dataset = KGDataset(val_triples, self.entity2id, self.relation2id)\n",
    "        eval_loader = DataLoader(eval_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "        self.eval()\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for head, relation, tail in eval_loader:\n",
    "                head, relation, tail = head.to(self.device), relation.to(self.device), tail.to(self.device)\n",
    "                \n",
    "                nodes = list(set(head.tolist()))\n",
    "                data = self.create_graph_data(nodes, val_triples).to(self.device)\n",
    "                all_embed = self.forward(data)\n",
    "                head_embed = all_embed[head]\n",
    "                relation_embed = self.relation_embedding(relation)\n",
    "                embed = torch.cat((head_embed, relation_embed), dim=1)\n",
    "                output = self.fc(embed)\n",
    "                predicted_tail = torch.argmax(output, dim=1)\n",
    "                total_correct += (predicted_tail == tail).sum().item()\n",
    "                total_samples += len(tail)\n",
    "        accuracy = total_correct / total_samples\n",
    "        return accuracy\n",
    "\n",
    "    def predict(self, triples, top_k=10):\n",
    "        self.eval()\n",
    "        dataset = predDataset(triples, self.entity2id, self.relation2id)\n",
    "        loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        results = []\n",
    "        id2entity = {v: k for k, v in self.entity2id.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for head, relation in loader:\n",
    "                head, relation= head.to(self.device), relation.to(self.device)\n",
    "                nodes = list(set(head.tolist()))\n",
    "                data = self.create_graph_data(nodes, []).to(self.device)\n",
    "                all_embed = self.forward(data)\n",
    "                head_embed = all_embed[head]\n",
    "                relation_embed = self.relation_embedding(relation)\n",
    "                embed = torch.cat((head_embed, relation_embed), dim=1)\n",
    "                output = self.fc(embed)\n",
    "                _, top_indices = torch.topk(output, top_k, dim=1)\n",
    "\n",
    "                for idx_list in top_indices:\n",
    "                    top_entities = [id2entity[idx.item()] for idx in idx_list]\n",
    "                    results.append(top_entities)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def save_model(self, path):\n",
    "        torch.save({\n",
    "            'model_state_dict': self.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'entity2id': self.entity2id,\n",
    "            'relation2id': self.relation2id\n",
    "        }, path)\n",
    "        print(f'Model saved to {path}')\n",
    "\n",
    "    def load_model(self, path):\n",
    "        checkpoint = torch.load(path)\n",
    "        self.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.entity2id = checkpoint['entity2id']\n",
    "        self.relation2id = checkpoint['relation2id']\n",
    "        print(f'Model loaded from {path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5091e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   0%|          | 0/6213 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for dimension 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m rDic \u001b[38;5;241m=\u001b[39m relation2text\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m RetrieveAndReadFramework(train, eDic, rDic, entity_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, relation_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m     12\u001b[0m                                  num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, num_gnn_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mva\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate_model(va)\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39msave_model(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./trained/final.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 90\u001b[0m, in \u001b[0;36mRetrieveAndReadFramework.train_model\u001b[0;34m(self, train_triples, val_triples)\u001b[0m\n\u001b[1;32m     88\u001b[0m nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(head\u001b[38;5;241m.\u001b[39mtolist()))\n\u001b[1;32m     89\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_graph_data(nodes, train_triples)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 90\u001b[0m all_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m head_embed \u001b[38;5;241m=\u001b[39m all_embed[head]\n\u001b[1;32m     92\u001b[0m relation_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelation_embedding(relation)\n",
      "Cell \u001b[0;32mIn[15], line 76\u001b[0m, in \u001b[0;36mRetrieveAndReadFramework.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     74\u001b[0m x, edge_index \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgnn_layers:\n\u001b[0;32m---> 76\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.conda/envs/GEO/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/GEO/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/GEO/lib/python3.9/site-packages/torch_geometric/nn/conv/gcn_conv.py:241\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    239\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[0;32m~/.conda/envs/GEO/lib/python3.9/site-packages/torch_geometric/nn/conv/gcn_conv.py:99\u001b[0m, in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m num_nodes \u001b[38;5;241m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_self_loops:\n\u001b[0;32m---> 99\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43madd_remaining_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), ), dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    104\u001b[0m                              device\u001b[38;5;241m=\u001b[39medge_index\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.conda/envs/GEO/lib/python3.9/site-packages/torch_geometric/utils/loop.py:623\u001b[0m, in \u001b[0;36madd_remaining_self_loops\u001b[0;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Adds remaining self-loop :math:`(i,i) \\in \\mathcal{E}` to every node\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;124;03m:math:`i \\in \\mathcal{V}` in the graph given by :attr:`edge_index`.\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;124;03mIn case the graph is weighted or has multi-dimensional edge features\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;124;03m    tensor([0.5000, 0.5000, 1.0000, 1.0000]))\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    622\u001b[0m N \u001b[38;5;241m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[0;32m--> 623\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m!=\u001b[39m edge_index[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    625\u001b[0m device \u001b[38;5;241m=\u001b[39m edge_index\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting():\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for dimension 0 with size 0"
     ]
    }
   ],
   "source": [
    "train_set = pd.read_csv(\"MyData/train.csv\")[['Head', 'Relation', 'Tail']]\n",
    "va_set = pd.read_csv(\"MyData/vali.csv\")[['Head', 'Relation', 'Tail']]\n",
    "train = [tuple(row) for row in train_set.itertuples(index=False)]\n",
    "va = [tuple(row) for row in va_set.itertuples(index=False)]\n",
    "test_set = pd.read_csv(\"MyData/test.csv\")[['Head', 'Relation']]\n",
    "test = [tuple(row) for row in test_set.itertuples(index=False)]\n",
    "relation2text = pd.read_csv(\"MyData/relation.csv\", encoding='UTF-8')[['Name', 'Text', 'ID']]\n",
    "entity2text = pd.read_csv(\"MyData/entity.csv\", encoding='UTF-8')[['Name', 'Text', 'ID']]\n",
    "eDic = entity2text.set_index('Name')['ID'].to_dict()\n",
    "rDic = relation2text.set_index('Name')['ID'].to_dict()\n",
    "model = RetrieveAndReadFramework(train, eDic, rDic, entity_dim=16, relation_dim=16, lr=0.0001, batch_size=200,\n",
    "                                 num_epochs=50, num_gnn_layers=5)\n",
    "\n",
    "model.train_model(train_triples=train[:500], val_triples=va)\n",
    "model.evaluate_model(va)\n",
    "model.save_model(path=\"./trained/final.pt\")\n",
    "result = model.predict(test)\n",
    "result = pd.DataFrame(result)\n",
    "test_set = pd.concat([test_set, result], axis=1)\n",
    "test_set.to_csv(\"result.tsv\", header=None, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dc26c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GEO",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
